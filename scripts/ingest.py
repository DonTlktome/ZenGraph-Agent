import os
import torch
import chromadb
from tqdm import tqdm
from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Settings, StorageContext
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.vector_stores.chroma import ChromaVectorStore

# --- é…ç½® ---
CLEANED_DATA_PATH = "./data/sutras/cbeta-text-cleaned"
CHROMA_DB_PATH = "./chroma_db"
PROCESSED_LOG = "processed_files.log"

def init_settings():
    print("--- ğŸ§  åˆå§‹åŒ– Embedding æ¨¡å‹ (å¼€å¯ GPU åŠ é€Ÿ) ---")
    device = "cuda" if torch.cuda.is_available() else ("mps" if torch.backends.mps.is_available() else "cpu")
    Settings.embed_model = HuggingFaceEmbedding(
        model_name="BAAI/bge-small-zh-v1.5",
        device=device,
        embed_batch_size=128
    )
    Settings.llm = None
    Settings.chunk_size = 1024

def run_ingest():
    init_settings()
    
    # 1. è¿æ¥ ChromaDB
    db = chromadb.PersistentClient(path=CHROMA_DB_PATH)
    chroma_collection = db.get_or_create_collection("buddhist_sutras")
    vector_store = ChromaVectorStore(chroma_collection=chroma_collection)
    storage_context = StorageContext.from_defaults(vector_store=vector_store)

    # 2. åŠ è½½ç°æœ‰ç´¢å¼•
    index = VectorStoreIndex.from_vector_store(vector_store, storage_context=storage_context)

    # 3. è¯»å–æ–­ç‚¹è®°å½•
    processed_files = set()
    if os.path.exists(PROCESSED_LOG):
        with open(PROCESSED_LOG, "r", encoding="utf-8") as f:
            processed_files = set(line.strip() for line in f)

    # 4. æ‰«æå¾…å¤„ç†æ–‡ä»¶
    all_files = []
    for root, _, files in os.walk(CLEANED_DATA_PATH):
        for f in files:
            if f.endswith(".txt"):
                f_path = os.path.abspath(os.path.join(root, f))
                if f_path not in processed_files:
                    all_files.append(f_path)

    print(f"--- ğŸ“Š è¿›åº¦ç»Ÿè®¡: å·²å…¥åº“ {len(processed_files)} | å¾…å¤„ç† {len(all_files)} ---")

    # 5. åˆ†æ‰¹å¢é‡å…¥åº“
    batch_size = 100 
    for i in range(0, len(all_files), batch_size):
        batch = all_files[i : i + batch_size]
        
        # åŠ è½½è¿™ 100 ä¸ªæ–‡ä»¶
        reader = SimpleDirectoryReader(input_files=batch)
        documents = reader.load_data()
        
        # é€ä¸ªæ’å…¥å¹¶è®°å½•æ—¥å¿—
        for doc in documents:
            index.insert(doc)
            with open(PROCESSED_LOG, "a", encoding="utf-8") as f:
                # è®°å½•ç»å¯¹è·¯å¾„ï¼Œç¡®ä¿å”¯ä¸€æ€§
                f.write(os.path.abspath(doc.metadata.get("file_path", "")) + "\n")
        
        print(f"--- âœ… å·²å®Œæˆæ‰¹æ¬¡: {i//batch_size + 1} ({i+len(batch)}/{len(all_files)}) ---")

    print("--- ğŸ† æ­å–œï¼å…¨é‡æ•°æ®å…¥åº“å®Œæˆ ---")

if __name__ == "__main__":
    run_ingest()